{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abroad-chaos",
   "metadata": {},
   "source": [
    "![header](https://dbdmg.polito.it/wordpress/wp-content/uploads/2021/05/data_viz_header.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-cocktail",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this laboratory, you will get acquainted to the basic visualization techniques for the Exploratory Data Analysis (EDA). You will deal with charts to\n",
    "- analyze a data distribution, like **histograms**, **boxplots** and **violin plots**\n",
    "- explore relationships and (linear) correlations in your data, like **scatterplots** or **heatmaps**\n",
    "- visualize the trend and some salient information of a **time series**.\n",
    "\n",
    "Choosing the right type of chart for the type of data at hand is a never ending job. Some [communities](https://www.reddit.com/r/dataisbeautiful/) took it seriously since a while. You will soon find yourself eager to test many approaches: this laboratory will help you getting started.  \n",
    "\n",
    "## Structure\n",
    "\n",
    "Each main section of the notebook introduces one of the chart categories listed above. Within the sections, you will find a brief description of type of plot you are required to build, along with a short snippet of code that produces the chart on syntetic data.\n",
    "\n",
    "The whole notebook is written in **Python**. The code level is introductory: if your are a Python master, bear with me. On the other hand, not all the functions are described, but their functioning can be easily inferred either by the name or the output.   \n",
    "\n",
    "For your convenience, some parts of the notebook are pre-compiled, we filled the boilerplate code for you. Although the notebook is sequential, each section is self-contained: feel free to skip back and forth you are more interested in specific parts.\n",
    "  \n",
    "---\n",
    " \n",
    "So, to recap. Let's say your client provides you and your team a large set of raw, unprocessed data and you are the one in charge to do a first EDA pass. And you happen to know Python.\n",
    "\n",
    "![Data Viz](https://venngage-wordpress.s3.amazonaws.com/uploads/2020/06/image17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-adventure",
   "metadata": {},
   "source": [
    "# Before we start: Python & Co.\n",
    "\n",
    "Python is the *standard de-facto* ecosystem for data scientists and practitionaires. If I had to summarized its advantages over other languages like R, or even some GUI-enabled tools, I would say:\n",
    "\n",
    "- a large, well-documented standard library, and a *huge* number of third-part libraries for virtually *everything* you need\n",
    "- a large, supportive community with a lot of resources\n",
    "- modern Python keeps the syntax at a minimum. To run data science and visualization experiments, the python code almost reduces to *plain english*\n",
    "- a series of online tools that let you experiment with the language: you only need a Google Account to create [Colab](https://colab.research.google.com/notebook) Notebooks, and the same applies for [Kaggle](https://www.kaggle.com/), [Deepnote](https://deepnote.com/), and many more.\n",
    "\n",
    "In this laboratory, we will use three popular libraries: [NumPy](https://numpy.org/devdocs/index.html), [pandas](https://pandas.pydata.org/docs/) and [seaborn](https://seaborn.pydata.org/). Let's run the cell below to check and install all the dependecies for these libraries (do not worry about warnings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-craft",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --user numpy\n",
    "!pip install --quiet --user pandas\n",
    "!pip install --quiet --user seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-missile",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "\n",
    "We can import them now (along with other useful standard libraries) and provide an alias with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# set the style for all the charts in the notebook\n",
    "sns.set_theme(\"notebook\")\n",
    "\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-universal",
   "metadata": {},
   "source": [
    "### Data Manipulation\n",
    "\n",
    "NumPy and Pandas let you easily handle numerical arrays and tabular data respectively.\n",
    "Simply put, NumPy (or numpy in the following) is your best companion for the Geometry class, while Pandas provides you a table-like access to your data (with index and column names, and so on). \"Tables\" in pandas are known as DataFrames.\n",
    "\n",
    "They have been thoroughly covered in the course Data Science Lab: process and methods at Politecnico di Torino. If you are interest, feel free to visit the [course website](https://dbdmg.polito.it/wordpress/teaching/data-science-lab-process-and-methods-2020-2021/) for slides and laboratories.\n",
    "\n",
    "To give a practical example, let's see how we can create a simple array with all the integers between 0 (included) and 100 (excluded) in numpy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-processor",
   "metadata": {},
   "source": [
    "or a 3x3 matrix with random floating point numbers from 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random((3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-honolulu",
   "metadata": {},
   "source": [
    "For pandas instead, let's create a toy table-like dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Age\": [22, 43, 19, 23, 55],\n",
    "        \"Gender\": [\"Male\", \"Female\", \"Female\", \"Male\", \"Female\"],\n",
    "        \"Origin\": [\"Italy\", \"France\", \"France\", \"USA\", \"USA\"]\n",
    "    }\n",
    ")\n",
    "toy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-symposium",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "The most used library for data visualization in python is [matplotlib](https://matplotlib.org/). However, in this laboratory, you will use **seaborn**.\n",
    "Seaborn is a matplotlib wrapper which provides simpler-to-use, high-level APIs to produce charts with better quality and lower effort. It integrates pandas off-the-shelf and provides [an extended list](https://seaborn.pydata.org/api.html) of chart types already implemented. You better take a look at it: most of the cases the chart you are trying to achieve manually is already there.\n",
    "\n",
    "If you want to do something low-level, like changing the size for all the future figures in the notebook, you have to use matplolib. Let us do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-windsor",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "You will deal with two different types of data.\n",
    "\n",
    "First, we will focus on tabular data, with the [Stroke Prediction Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset).\n",
    "\n",
    "Next, we will do some finance. We collected the ticker prices of eight publicly traded companies, namely Amazon (AMZN), AAPL (AAPL), Alphabet Inc (GOOG), Microsoft (MSFT), Johnson & Johnson (JNJ), Pfizer (PFE), Sanofi (SNY), and AstraZeneca (AZN). Not by coincidence, four of them belong to the tech sector, and the rest to healthcare.\n",
    "\n",
    "Run the cell below to download and extract the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://dbdmg.polito.it/wordpress/wp-content/uploads/2021/05/datasets_Data_Theory_Python.zip -O datasets.zip\n",
    "!unzip -qu datasets.zip\n",
    "!rm datasets.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-single",
   "metadata": {},
   "source": [
    "# Exercise 1. Tabular Data: Stroke Prediction Dataset\n",
    "\n",
    "The dataset collects information on patients that are likely to get stroke. Each row of the dataset contains relevant information about a patient, like gender, age, various diseases, and smoking status.\n",
    "\n",
    "(From Kaggle) The attributes are:\n",
    "\n",
    "- **id**: unique identifier\n",
    "- **gender**: \"Male\", \"Female\" or \"Other\"\n",
    "- **age**: age of the patient\n",
    "- **hypertension**: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
    "- **heart_disease**: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
    "- **ever_married**: \"No\" or \"Yes\"\n",
    "- **work_type**: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
    "- **Residence_type**: \"Rural\" or \"Urban\"\n",
    "- **avg_glucose_level**: average glucose level in blood\n",
    "- **bmi**: body mass index\n",
    "- **smoking_status**: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
    "- **stroke**: 1 if the patient had a stroke or 0 if not\n",
    "\n",
    "*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient\n",
    "\n",
    "Reading and parsing the dataset with pandas is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_df = pd.read_csv(join(\"datasets\", \"healthcare-dataset-stroke-data.csv\"))\n",
    "stroke_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-bubble",
   "metadata": {},
   "source": [
    "## Explore Data Distribution\n",
    "\n",
    "Let's now build some of the most common charts to analyze data distribution: **histograms**, **box plots** and **violin plots** with seaborn. More advanced configurations can be achieved with **displot** (generic distribution plot), or **catplot** for \"category plot\".\n",
    "\n",
    "Before addressing the real dataset, let's create a few syntetic data points to test the searborn APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt = np.random.random(1000)\n",
    "synt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-wilderness",
   "metadata": {},
   "source": [
    "We can then plug them into one of the various *histplot*, *boxplot* or *violinplot* already available in seaborn. *Note that boxplots and violinplots cannot directly be applied to non-numerical variables as they show distributions. Histplot, instead, can display simple counts for each value of a categorical variable.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y=synt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-symposium",
   "metadata": {},
   "source": [
    "From the output, we can see that the method np.random.random samples points from a uniform distribution between 0 and 1.\n",
    "As previously mentioned, seaborn comes integrated with pandas. You can call any of its plotting methods specifying a dataframe to the `data` argument and a column name for the other parameters, like `x` in the previous cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"Age\", data=toy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-closure",
   "metadata": {},
   "source": [
    "Across almost all its functions, seaborn let's you easily separate the plot based on a variable of interest. You can specify it with the parameter `hue`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=\"Age\", hue=\"Gender\", data=toy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-diabetes",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's now analyze the real stroke dataset. Specifically, try to answer the following questions:\n",
    "\n",
    "- Q1: what is the age distribution of patients?\n",
    "- Q2: are there more male or female smokers?\n",
    "- Q3: how is the age distributed for people who got stroke and those who did not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: YOUR CODE HERE (~10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-medline",
   "metadata": {},
   "source": [
    "## Explore Data Correlation\n",
    "\n",
    "Let's now focus on exploring data correlation in our dataset. We will mainly use scatterplot and, again, **displot**. The latter is a versatile function that accepts either a single or two inputs.\n",
    "\n",
    "Again, let's start with a few syntetic data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "synt = np.random.normal(size=(1000, 2))\n",
    "synt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=synt[:, 0], y=synt[:, 1], kind=\"hist\", rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-curve",
   "metadata": {},
   "source": [
    "Here we changed the generator: np.random.normal, as per its name, draws data point from a normal distribution. The displot plots the first 1000 points (`synt[:, 0]`) on the horizontal axis and the second 1000 points (`synt[:, 1]`) on the vertical axis. The `rug=True` its a nice addition: it adds small segments corresponding to data points on a single dimension (mathematicians will tell you that those are the two marginal distributions).\n",
    "\n",
    "Similarly, the **scatterplot** results in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=synt[:, 0], y=synt[:, 1], alpha=0.5) # alpha: \"opacity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-acoustic",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's now analyze the real stroke dataset. Specifically, try to answer the following questions:\n",
    "\n",
    "- Q1: what is the correlation between the body mass index and average glucose level?\n",
    "- Q2: what is the correlation between the body mass index and average glucose level, separately by stroke yes/no?\n",
    "- Q3: what it the correlation between the body mass index, the average glucose level, and the age?\n",
    "- Q4: what it the correlation between the body mass index, the average glucose level, the age, and the probability of get stroke?\n",
    "\n",
    "*Note: to answer Q2 and Q3 dive into the documentation of scatterplot/displot and search for color and/or size*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: YOUR CODE HERE (~10 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-conservative",
   "metadata": {},
   "source": [
    "## The easiest way\n",
    "\n",
    "Seaborn provides you a single method that generates multiple type of correlation plots in a single figure. Let's try **pairplot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=stroke_df, vars=[\"age\", \"bmi\", \"avg_glucose_level\"], hue=\"stroke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-installation",
   "metadata": {},
   "source": [
    "# Exercise 2. Financial Time Series\n",
    "\n",
    "We switch now to a completely different domain: financial time series. We have the candlestick values (Open, High, Low, Close, Adjusted Close, and Volume) of eight public companies. The stock data is separated in different files. Each file contains the OHLCV values in tabular format: each row corresponds to a trading day. Our data is two-years long, from May 1, 2019 to May 1, 2021.\n",
    "\n",
    "The time series will give use the opportunity two use two more types of chart: **lineplot** and **heatmap**.\n",
    "First, we load them into a dictionary with company names as keys and pandas dataframes as values.\n",
    "\n",
    "Then, for each ticker, we also add a new column representing the *percentage_change* between the current day's close and the previous one.\n",
    "\n",
    "$$ pct\\_change_t = \\frac{(close_t - close_{t-1})}{close_{t-1}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = [\"AAPL\", \"AMZN\", \"GOOG\", \"MSFT\"] \n",
    "healthcare = [\"JNJ\", \"PFE\", \"SNY\", \"AZN\"]\n",
    "tickers = tech + healthcare\n",
    "\n",
    "ticker_dfs = {\n",
    "    tick: pd.read_csv(join(\"datasets\", f\"{tick}.csv\"), parse_dates=True, index_col=\"Date\")\n",
    "    for tick in tickers\n",
    "}\n",
    "\n",
    "# add pct_change\n",
    "for _, tick_df in ticker_dfs.items():\n",
    "    tick_df[\"pct_change\"] = tick_df[\"Close\"].pct_change()\n",
    "\n",
    "ticker_dfs[\"AAPL\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-affair",
   "metadata": {},
   "source": [
    "## Explore trend and search co-trending stocks\n",
    "\n",
    "The syntax of seaborn methods is the same also for the next charts. If we want to analyze a single series, we can simply pass it to the parameter `data`, seaborn will take care of the rest (axis scaling, choose the right labels for days, etc.).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=ticker_dfs[\"AAPL\"][\"Close\"], label=\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-theme",
   "metadata": {},
   "source": [
    "In all the previous examples we run a single plot per cell. Try now to execute several lineplot in the same cell, specifically plot:\n",
    "- Q1: the Close series for all the healthcare stocks\n",
    "- Q2: the pct_change series for all the tech stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: YOUR CODE HERE (~10 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-disposition",
   "metadata": {},
   "source": [
    "The last chart is pretty much garbage. Let's **search for co-trending behaviors** in another way. Let's go through the following steps:\n",
    "1. collect in a new dataframe only the pct_change series\n",
    "2. compute the [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) for each pair of series. A strong correlation of any two series signals that the two stocks were moving very similarly\n",
    "3. plot a heatmap chart to easily spot correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change_df = pd.DataFrame({tick: ticker_dfs[tick][\"pct_change\"] for tick in tickers})\n",
    "pct_change_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pct_change_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-inspiration",
   "metadata": {},
   "source": [
    "We can still improved the chart a bit. Since we know that the Pearson correlation goes from -1 (negatively correlated - if one increase, the other one decreases) to 1 (positively correlated - if one increases, the other one does the same), **we can set the color scale to match the range \\[-1, 1\\]. Search the heatmap documentation and add this change**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: YOUR CODE HERE (~5 mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-theorem",
   "metadata": {},
   "source": [
    "# Conclusion (and what we have left aside)\n",
    "\n",
    "In this laboratory we have introduced many of the basic types of charts offered by the seaborn library. The API is vaste though, and we are far from having completely explored it all. Furthermore, note that custom, low-level charts require the a solid knowledge of the inner matplotlib functioning, but that went beyond the scope of the laboratory. \n",
    "\n",
    "On the other hand, we have left aside other charting strategies, such as **part-whole** visualizations, or plots that help visualizing **rankings**.\n",
    "\n",
    "Finally, other charts complete the landscape. **Maps** are a completely different matter, and require specific, more advanced libraries. The same applies to **wordclouds** (and in general textual representations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-cricket",
   "metadata": {},
   "source": [
    "# Bonus. Interactivity\n",
    "\n",
    "We want to give you a final pointer to the topic of interactive charting. One of the most used open source charting library for interactivity is [plotly](https://plotly.com/graphing-libraries/). The library is available for Python, R, and Javascript.\n",
    "\n",
    "The class names are different, the name of the functions are different but the syntax of the [plotly-express](https://plotly.com/python/plotly-express/) interface is similar to seaborn.\n",
    "\n",
    "The following cells install plotly for python and produce the lineplot and the correlation heatmap drawn with seaborn before, but with interactivity enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-coral",
   "metadata": {},
   "source": [
    "#### DISCLAIMER\n",
    "\n",
    "At the time of writing, Plotly is not fully supported by Jupyter Lab. In order to run and see the results of the last cell, you have to switch to the classical Jupyter Notebook interface. You can do it by simply replacing *lab* with *tree* in the current URL string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --user plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(ticker_dfs[\"AAPL\"][\"Close\"], title=\"AAPL: Close Price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(pct_change_df.corr(), title=\"Close Price Correlation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-reasoning",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This notebook was created by [Giuseppe Attanasio](https://gattanasio.cc), PhD student @ Politecnico di Torino.\n",
    "You are free to download, edit and publish newer versions of the notebook.\n",
    "\n",
    "Credit to *fedesoriano* for sharing the Stroke Prediction Dataset on Kaggle.\n",
    "Ticker data is retrieved from Yahoo Finance.\n",
    "\n",
    "*v1: 02/05/2021*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
